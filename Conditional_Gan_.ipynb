{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQJmRQRVK3Z",
        "outputId": "702ed9a0-637f-4c02-ab8f-dd29a3b31cd3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.isdir(\"Conditional-Gan\"):\n",
        "  os.makedirs(\"Conditional-Gan\")\n",
        "%cd Conditional-Gan"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2Y4zuXoVKSw",
        "outputId": "e55bd477-0249-4611-aeca-08dcacf53965"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Conditional-Gan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wFvkoyjbrPwI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D,Dropout,Input,UpSampling2D,BatchNormalization,Flatten,Dense,Reshape,Embedding,concatenate,MaxPooling2D\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator(input_shape,n_classes=10):\n",
        "  inp_img=Input(shape=input_shape ,name=\"image\")\n",
        "  inp_label=Input(shape=(1,),name=\"label\")\n",
        "  emb=Embedding(n_classes,50)(inp_label)\n",
        "  il=Dense(28*28,activation=\"relu\")(emb)\n",
        "  il=Reshape((28,28,1))(il)\n",
        "\n",
        "\n",
        "  con=concatenate([inp_img,il])\n",
        "  x=Conv2D(64, 3, activation = 'relu')(con)\n",
        "  x=MaxPooling2D((2,2))(x)\n",
        "  x=Conv2D(64, 3, activation= 'relu')(x)\n",
        "  x=MaxPooling2D((2,2))(x)\n",
        "\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(32,activation='relu')(x)\n",
        "  output=Dense(1,activation=\"sigmoid\")(x)\n",
        "  model = Model(inputs=[inp_img,inp_label],outputs=output,name=\"discrminator\")\n",
        "  model.summary()\n",
        "  model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=2e-4), metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "OEIFi34frleT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_model=discriminator((28,28,1),n_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOYPKc6LroNg",
        "outputId": "d798122f-a215-4d0b-c72a-95e46001e2fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discrminator\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " label (InputLayer)             [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 1, 50)        500         ['label[0][0]']                  \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1, 784)       39984       ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " image (InputLayer)             [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " reshape (Reshape)              (None, 28, 28, 1)    0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 28, 28, 2)    0           ['image[0][0]',                  \n",
            "                                                                  'reshape[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 26, 26, 64)   1216        ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 13, 13, 64)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 11, 11, 64)   36928       ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 64)    0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1600)         0           ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 32)           51232       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 129,893\n",
            "Trainable params: 129,893\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Generator(latent_dim,n_classes):\n",
        "\n",
        "  in_label=Input(shape=(1,),name=\"input_label\")\n",
        "  emb=Embedding(n_classes,50)(in_label)\n",
        "  n=7*7*128\n",
        "  de=Dense(n,activation='relu')(emb)\n",
        "  reshape=Reshape((7,7,128))(de)\n",
        "\n",
        "  in_lat=Input(shape=(latent_dim,),name=\"latent_input\")\n",
        "  nod=7*7*128\n",
        "  lat=Dense(nod,activation='leaky_relu')(in_lat)\n",
        "  lat=Reshape((7,7,128))(lat)\n",
        "  x=concatenate([lat,reshape])\n",
        "  x=UpSampling2D((2,2))(x)\n",
        "  x=Conv2D(128,3,padding='same',activation='leaky_relu')(x)\n",
        "  x=UpSampling2D((2,2))(x)\n",
        "  x=Conv2D(64,3,padding='same',activation='leaky_relu')(x)\n",
        "  output=Conv2D(1,3,padding='same',activation='sigmoid')(x)\n",
        "  model=Model([in_lat,in_label],output,name='Generator')\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "g78buyICropA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G_model=Generator(100,n_classes=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HancqJJsrtpw",
        "outputId": "ec5f1256-0c88-4a96-948a-d5432b5ad28a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Generator\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_label (InputLayer)       [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " latent_input (InputLayer)      [(None, 100)]        0           []                               \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, 1, 50)        500         ['input_label[0][0]']            \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 6272)         633472      ['latent_input[0][0]']           \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 1, 6272)      319872      ['embedding_1[0][0]']            \n",
            "                                                                                                  \n",
            " reshape_2 (Reshape)            (None, 7, 7, 128)    0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# get noise and label inputs from generator model\n",
        "\tgen_noise, gen_label = g_model.input\n",
        "\t# get image output from the generator model\n",
        "\tgen_output = g_model.output\n",
        "\t# connect image output and label input from generator as inputs to discriminator\n",
        "\tgan_output = d_model([gen_output, gen_label])\n",
        "\t# define gan model as taking noise and label and outputting a classification\n",
        "\tmodel = Model([gen_noise, gen_label], gan_output)\n",
        "\t# compile model\n",
        "\topt = Adam(learning_rate=2e-4)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "GbtRjVdvtWBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gan=define_gan(G_model,D_model)"
      ],
      "metadata": {
        "id": "hhj0cAnTtaGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load fashion mnist images\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) =  tf.keras.datasets.fashion_mnist.load_data()\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = np.expand_dims(trainX, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = X/255.\n",
        "\treturn [X, trainy]\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# split into images and labels\n",
        "\timages, labels = dataset\n",
        "\t# choose random instances\n",
        "\tix = np.random.randint(0, images.shape[0], n_samples)\n",
        "\t# select images and labels\n",
        "\tX, labels = images[ix], labels[ix]\n",
        "\t# generate class labels\n",
        "\ty = tf.ones((n_samples, 1))\n",
        "\treturn [X, labels], y"
      ],
      "metadata": {
        "id": "bIaNvMobrtnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples, n_classes=10):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = np.random.randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tz_input = x_input.reshape(n_samples, latent_dim)\n",
        "\t# generate labels\n",
        "\tlabels = np.random.randint(0, n_classes, n_samples)\n",
        "\treturn [z_input, labels]\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tz_input, labels_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\timages = generator.predict([z_input, labels_input],verbose=0)\n",
        "\t# create class labels\n",
        "\ty = np.zeros((n_samples, 1))\n",
        "\treturn [images, labels_input], y"
      ],
      "metadata": {
        "id": "zNevNkEkrtky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import Progbar\n",
        "\n",
        "def train(g_model, d_model, gan_model, dataset, latent_dim, epochs=100, n_batch=128):\n",
        "    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n",
        "    half_batch = int(n_batch / 2)\n",
        "\n",
        "    # Manually enumerate epochs\n",
        "    for epoch in range(1,epochs+1):\n",
        "        print(f\"Epoch {epoch}/{epochs}\")\n",
        "        # Initialize the progress bar\n",
        "        progbar = Progbar(bat_per_epo)\n",
        "        \n",
        "        # Enumerate batches over the training set\n",
        "        for j in range(bat_per_epo):\n",
        "            # Get randomly selected 'real' samples\n",
        "            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n",
        "            \n",
        "            # Update discriminator model weights\n",
        "            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n",
        "            \n",
        "            # Generate 'fake' examples\n",
        "            [X_fake, labels], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "            \n",
        "            # Update discriminator model weights\n",
        "            d_loss2, _ = d_model.train_on_batch([X_fake, labels], y_fake)\n",
        "            \n",
        "            # Prepare points in latent space as input for the generator\n",
        "            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n",
        "            \n",
        "            # Create inverted labels for the fake samples\n",
        "            y_gan = np.ones((n_batch, 1))\n",
        "            \n",
        "            # Update the generator via the discriminator's error\n",
        "            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n",
        "            \n",
        "            # Update the progress bar with the current batch metrics\n",
        "            progbar.update(j + 1, values=[(\"d1\", d_loss1), (\"d2\", d_loss2), (\"g\", g_loss)])\n",
        "        # Save the generator model\n",
        "        g_model.save('generator.hdf5')\n",
        "        d_model.save('Discriminator.hdf5')\n"
      ],
      "metadata": {
        "id": "RdscNIeOx64s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "# train model\n",
        "train(G_model, D_model, gan, dataset, latent_dim, epochs=500)"
      ],
      "metadata": {
        "id": "B_UBSBfbrtf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2K-bnFUt1LFh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}